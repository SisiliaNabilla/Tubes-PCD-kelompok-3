{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result/preprocessing.csv')\n",
    "X_features = data.drop('label', axis=1).values\n",
    "y = data['label'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_features_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_features_scaled, y_encoded, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 200], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 6, 8, 10, 12]}\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(x_train, y_train)\n",
    "y_pred_rf = best_rf.predict(x_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "svc_model = SVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "y_pred_svc = svc_model.predict(x_test)\n",
    "\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc, average='weighted', zero_division=0)\n",
    "recall_svc = recall_score(y_test, y_pred_svc, average='weighted', zero_division=0)\n",
    "f1_svc = f1_score(y_test, y_pred_svc, average='weighted', zero_division=0)\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(x_train, y_train)\n",
    "y_pred_knn = knn_model.predict(x_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted', zero_division=0)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted', zero_division=0)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted', zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_rf, 'Random Forest Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, y_pred_svc, 'SVC Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN Confusion Matrix')\n",
    "\n",
    "def print_evaluation_metrics(accuracy, precision, recall, f1, model_name):\n",
    "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"{model_name} Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"{model_name} Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"{model_name} F1 Score: {f1 * 100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print_evaluation_metrics(accuracy_rf, precision_rf, recall_rf, f1_rf, 'Random Forest')\n",
    "print_evaluation_metrics(accuracy_svc, precision_svc, recall_svc, f1_svc, 'SVC')\n",
    "print_evaluation_metrics(accuracy_knn, precision_knn, recall_knn, f1_knn, 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_rf.feature_importances_\n",
    "importance_threshold = 0.01\n",
    "important_features = np.where(feature_importances > importance_threshold)[0]\n",
    "\n",
    "if important_features.size == 0:\n",
    "    important_features = np.arange(X_features_scaled.shape[1])\n",
    "\n",
    "X_features_selected = X_features_scaled[:, important_features]\n",
    "\n",
    "x_train_sel, x_test_sel, y_train_sel, y_test_sel = train_test_split(X_features_selected, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "best_rf.fit(x_train_sel, y_train_sel)\n",
    "y_pred_rf_sel = best_rf.predict(x_test_sel)\n",
    "accuracy_rf_sel = accuracy_score(y_test_sel, y_pred_rf_sel)\n",
    "precision_rf_sel = precision_score(y_test_sel, y_pred_rf_sel, average='weighted', zero_division=0)\n",
    "recall_rf_sel = recall_score(y_test_sel, y_pred_rf_sel, average='weighted', zero_division=0)\n",
    "f1_rf_sel = f1_score(y_test_sel, y_pred_rf_sel, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Random Forest with Selected Features:\")\n",
    "print_evaluation_metrics(accuracy_rf_sel, precision_rf_sel, recall_rf_sel, f1_rf_sel, 'Random Forest')\n",
    "\n",
    "plot_confusion_matrix(y_test_sel, y_pred_rf_sel, 'Random Forest with Selected Features Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(X_images, y_true, y_pred, title):\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            idx = random.randint(0, len(y_true) - 1)\n",
    "            ax[i, j].imshow(X_images[idx])\n",
    "            ax[i, j].set_title(f\"Pred: {le.inverse_transform([y_pred[idx]])[0]}\\nTrue: {le.inverse_transform([y_true[idx]])[0]}\")\n",
    "            ax[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = np.load('original_images.npy')\n",
    "\n",
    "visualize_predictions(original_images, y_test, y_pred_rf, 'Random Forest Predictions')\n",
    "visualize_predictions(original_images, y_test_sel, y_pred_rf_sel, 'Random Forest with Selected Features Predictions')\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'SVC', 'KNN', 'Random Forest with Selected Features'],\n",
    "    'Accuracy': [accuracy_rf, accuracy_svc, accuracy_knn, accuracy_rf_sel],\n",
    "    'Precision': [precision_rf, precision_svc, precision_knn, precision_rf_sel],\n",
    "    'Recall': [recall_rf, recall_svc, recall_knn, recall_rf_sel],\n",
    "    'F1 Score': [f1_rf, f1_svc, f1_knn, f1_rf_sel]\n",
    "})\n",
    "results.to_csv('model_evaluation_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
